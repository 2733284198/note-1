# Go语言服务中使用机器学习模型
由于目前大部分的机器学习模型使用python训练，而python作为一种解释性语言，它的性能往往不如人意，所以模型的部署一直是令人头疼的问题。还有就是机器学框架五花八门，模型数据没有统一的标准。比如A框架训练的模型，在B框架不能直接加载使用。这里主要介绍用Go语言开发的业务服务，如何应用TensortFlow或sklearn训练出来的模型。

## TensortFlow
TensortFlow 是google开源的机器学习框架，内核主要使用C++开发，外面包了一层python，通常使用Python进行训练。同时它还提供了其他语言的接口，比如C、C++、java、go等，这些主要用来部署模型的。这里我们介绍一下Go语言怎么使用训练好的模型。

### 通过sdk加载模型方式
TensortFlow训练出来的模型可以保存成一个目录，里面有多个文件，包含的模型相关的信息。TensortFlow官方提供了多种语言的sdk（包括go），可以加载这个目录，重新构建模型，然后我们就可以直接调用模型的预测函数。这种方法的优点是模型的训练和部署分离，模型的训练交给算法工程师去做，上线和部署交给开发工程师。因为是函数调用，没有网络损失，这种方式性能最好。众所周知，Go调C/C++都是通过cgo实现的。所以Go服务依赖TensortFlow编译出来的动态库文件，而本人之前在部署随机森林时，发现官方编译出来的动态库里面有些模块是没有编译进去的，所以需要自己编译。而编译过程中需要下载一些依赖的第三方库代码，又由于众所周知的原因，有些可能会失败。所以，如果不是对性能要求太高，不建议用这种方式。推荐使用下面介绍的Tensortflow Serving方式。

### 通过Tensortflow Serving方式
TensorFlow Serving是google开源的使用C++开发的一个服务系统，适用于部署机器学习模型，灵活、性能高、可用于生产环境。 TensorFlow Serving可以轻松部署新算法和实验，同时保持相同的服务器架构和API，它具有以下特性： 
- 支持模型版本控制和回滚
- 支持并发，实现高吞吐量
- 开箱即用，并且可定制化
- 支持多模型服务
- 支持批处理
- 支持热更新
- 支持分布式模型
- 易于使用的inference api
- 提供了gRPC和RESTful接口

这种方式就是要部署一个模型服务，它负责加载模型文件。业务服务通过网络接口调用模型服务，模型的升级对业务服务来说是无感的。为了更好的性能，建议使用gRPC接口。如果模型服务很轻量级，还可以将它和业务服务部署在同一个主机上，使用k8s部署就更方便了（都2020年了，还有不用k8s的公司吗，如果有，建议你们老板把CTO换了），只需将他们部署在一个同pod中，通过localhost就能访问。模型文件可以放在云盘上，比如阿里云的oss，模型服务通过挂载volume的方式将模型加到容器中，模型升级的时候只需替换云盘上的文件即可。

## sklearn
有时候通过Tensortflow训练的模型不太理想，于是有的算法工程师就用其他的框架训练，比如sklearn。sklearn是一个python项目，不支持其他语言。若是对性能要求不高还好，写一个python服务来加载模型文件，提供网络接口，业务服务通过网络接口调用模型服务，这样也能满足需求。后来发现了这个项目[m2cgen](https://github.com/BayesWitnesses/m2cgen)，它可以将sklearn训练的模型转化成其他语言的代码，然后我们就可以拿这些代码放到业务代码里面去编译和使用了。当然你用过会后发现，这些代码就是一堆的if、else语句，而且文件很大。本人之前做过的项目，有的模型转换出来的go语言代码有的有几百兆之多，一次要部署十几个模型，加起来超过2G的代码。你能想象编译有多困难吗，内存一定要大，本人之前一台8核32G的linux服务器，挂载一个200G的swap分区，跑了十几个小时。千万不要把模型代码和业务代码一起编译成可执行文件，正确的姿势应该是使用插件动态加载的方式。具体步骤就先将每个模型单独编译成一个动态库，也就是使用`go build --buildmode=plugin` 编译，业务代码中用plugin包来加载这些模型的动态库文件。为了实现模型的升级，可以将模型编译出来的动态库文件放在云盘上，业务服务的docker容器挂载模型在云盘上的目录，就可以像本地文件一样的加载了使用了。

## 总结
机器学习的应用还在出来早期，许多框架主要是面向研究型的，对应用方面的支持还不太友好，作为开发人员还需灵活应对各种挑战，才能立于不败之地。



